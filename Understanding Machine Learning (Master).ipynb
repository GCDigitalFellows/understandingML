{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Machine Learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Machine Learning\n",
    "\n",
    "## A broad definition\n",
    "* Traditional programs solve problems by following a specific set of steps specified by the programer (an Algorythm)\n",
    "* However we often find problems that can not really be solved by a traditional:\n",
    "    * Because there is no strict set of rules governing the phenomenon (randomness).\n",
    "    * Because we do not yet understand the rules understanding the phenomenon.\n",
    "\n",
    "\n",
    "* Broadly defined, machine learning is a family of algorythms that \"learn\" from observing a set of data (training data) and then can be used to process other data (unseen data) that is generated by a process supposed to be similar to the one that generated the training data.\n",
    "\n",
    "* In other words Machine learning methods extrapolate the behavior from some particular data to make predictions about data of that same kind. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But what do we mean by data?\n",
    "\n",
    "* Data for machine learning needs to have two things:\n",
    "    * A set of observations or measures (features)\n",
    "    * Another value that we want to predict (target) based on those observations. Often called the label\n",
    "    \n",
    "* Some examples of data for machine learning:\n",
    "    * The characteristics of a home and its neighbourhood (features) along with its sale price (target)\n",
    "    * The measurements of a plant's leaves (features) along with it's species (target)\n",
    "    * The demographic information of passengers of the titanic (features) along with whether they survived or not\n",
    "    \n",
    "* Sometimes it is not obvious what the features are but it is clear that we have data and a label, examplesinclude:\n",
    "    * Pictures along with their text descriptions\n",
    "    * Texts along with their genres\n",
    "    * Pictures of retinas along with whether or not they should be diagnosed with diabetic retinopathy\n",
    "    * Law case files along with the veredict\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two key distinctions\n",
    "\n",
    "* Classification V.S Regresion:\n",
    "    * In classification we have a certain number of classes and we want to assign training instances to those \n",
    "      classes, examples include:\n",
    "         * Determine if a tweet is positive or negative\n",
    "         * Determine if a bank transaction is normal or abnormal\n",
    "         * Distinguish whose faces are contained in a picture\n",
    "         * Determine if a given word in context is a noun, verb, preposition, etc\n",
    "    * In regression we are trying to determine a numerical value (a continuous variable) based on the feature data\n",
    "    as in .:\n",
    "      * Determine the price of a house based on it's real estate data\n",
    "      * Determine the likelihood that it will rain given weather data\n",
    "      * Estimate the value of a given share in the future \n",
    "\n",
    "\n",
    "* Supervised V.S Unsupervised:\n",
    "    * In supervised learning we provide the labels (the value of the target property) to the algorithm during training, most of the above examples are cases of suprevised learning.\n",
    "    * In unsupervised learning we hand only the features and we expect the algorythm to group them (clustering), we can then look to find common elements in the clusters.\n",
    "    * A third option is semi-supervised learning in which we might have labels for some of the data, we can then cluster the data and if we trust the unsupervised part asume that the unlabeled data in the cluster is going to have the same label as the labeled ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why do we care?\n",
    "* Machine learning is increasingly being used in research across fields, computational linguistics, digital humanities , computational biology, the list goes on.\n",
    "* Even if you don't use machine learning in your research the word around you uses it extensively.\n",
    "    * Recomendation systems are based on machine learning, youtube recomendations, add serving, etc all have some kind of machine learning behind them\n",
    "    * Credit scores are increasingly based on machine learning, as are insurance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and clean the data\n",
    "* Our data consists in the last 200 tweets (as of as of May 17th 2018 ) of each representative in the U.S Congress, available at: https://www.kaggle.com/kapastor/democratvsrepublicantweets, provided by Kyle Pastor\n",
    "* For each tweet we have:\n",
    "    * The party of the representative\n",
    "    * The twitter handle of the representatve\n",
    "    * The text of the tweet\n",
    "* We are going to try to learn to distinguish tweets from Republicans and tweets from Democrats (supervised classification)\n",
    "* We will use the text as our data and extract features from it\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Party</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Today, Senate Dems vote to #SaveTheInternet. P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @WinterHavenSun: Winter Haven resident / Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NBCLatino: .@RepDarrenSoto noted that Hurr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NALCABPolicy: Meeting with @RepDarrenSoto ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @Vegalteno: Hurricane season starts on June...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @EmgageActionFL: Thank you to all who came ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Hurricane Maria left approx $90 billion in dam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @Tharryry: I am delighted that @RepDarrenSo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @HispanicCaucus: Trump's anti-immigrant pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @RepStephMurphy: Great joining @WeAreUnidos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Party         Handle                                              Tweet\n",
       "0  Democrat  RepDarrenSoto  Today, Senate Dems vote to #SaveTheInternet. P...\n",
       "1  Democrat  RepDarrenSoto  RT @WinterHavenSun: Winter Haven resident / Al...\n",
       "2  Democrat  RepDarrenSoto  RT @NBCLatino: .@RepDarrenSoto noted that Hurr...\n",
       "3  Democrat  RepDarrenSoto  RT @NALCABPolicy: Meeting with @RepDarrenSoto ...\n",
       "4  Democrat  RepDarrenSoto  RT @Vegalteno: Hurricane season starts on June...\n",
       "5  Democrat  RepDarrenSoto  RT @EmgageActionFL: Thank you to all who came ...\n",
       "6  Democrat  RepDarrenSoto  Hurricane Maria left approx $90 billion in dam...\n",
       "7  Democrat  RepDarrenSoto  RT @Tharryry: I am delighted that @RepDarrenSo...\n",
       "8  Democrat  RepDarrenSoto  RT @HispanicCaucus: Trump's anti-immigrant pol...\n",
       "9  Democrat  RepDarrenSoto  RT @RepStephMurphy: Great joining @WeAreUnidos..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "tweetData = pd.read_csv('ExtractedTweets.csv')\n",
    "\n",
    "#A little bit of data cleaning\n",
    "# replace urls with special token\n",
    "urlPattern= re.compile(\"(http:\\/\\/www\\.|https:\\/\\/www\\.|http:\\/\\/|https:\\/\\/)?[a-z0-9]+([\\-\\.]{1}[a-z0-9]+)*\\.[a-z]{2,5}(:[0-9]{1,5})?(\\/.*)?\")\n",
    "tweetData[\"Tweet\"] = tweetData[\"Tweet\"].str.replace(urlPattern,\"<url>\")\n",
    "# Can you think of any other data cleaning measures?\n",
    "\n",
    "tweetData.head(10)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "* In order to feed the text to a classifier we need to extract numerical features\n",
    "* The classifier doesn't know what to look at in a tweet, but we can help it by computing __features__ that __might__ help\n",
    "* Features need to be numerical (categorial features as yes/no or a finite set of labels are also fair game since we can turn them into numbers)\n",
    "    * Presence or absence of something often gets encoded as 0 or 1\n",
    "    * A multiclass feature with n posible values can be represented as 1,2,3,...,n\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word length\n",
    "tweetData[\"Length\"] = np.vectorize(lambda x:len(x))(tweetData[\"Tweet\"])\n",
    "# Number of words\n",
    "tweetData[\"NumWords\"] = [len(tweet.split()) for tweet in tweetData[\"Tweet\"] ]\n",
    "# Is this a retweet\n",
    "tweetData[\"IsRT\"] = np.vectorize(lambda x : 1 if re.match(r\"RT\",x) else 0 )(tweetData[\"Tweet\"]) \n",
    "# Average word length\n",
    "tweetData[\"AVG_WL\"] = tweetData[\"NumWords\"]/tweetData[\"Length\"]\n",
    "# Number of at mentions\n",
    "tweetData[\"Ats\"] = np.vectorize(lambda x: len(re.findall(r'([^\\w]|^)@\\w+',x)))(tweetData[\"Tweet\"])\n",
    "# Number of hashtags\n",
    "tweetData[\"hashtags\"] = np.vectorize(lambda x: len(re.findall(r'([^\\w]|^)#\\w+',x)))(tweetData[\"Tweet\"])\n",
    "\n",
    "# Special words\n",
    "# chargedTerms = [\"fake news\", \"president\", \"bernie\", \"hillary\",\"pro-life\",\"pro-choice\",\"trump\",\"impeach\",\"alt-right\",\n",
    "#                \"mainstream media\",\"liberal\",\"family\",\"values\",\"troops\",\"russia\",\"florida\",\"potus\",\"taxreform\",\"<url>\",\n",
    "#                \"americans\"]\n",
    "\n",
    "# for term in chargedTerms:\n",
    "#     tweetData[term] = np.vectorize(lambda x: 1 if  re.search(term, x,re.IGNORECASE) else 0)(tweetData[\"Tweet\"])\n",
    "# tweetData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The development workflow\n",
    "* In order to use a machine learning system we must first train it on labeled data\n",
    "* But how will we know if it works?\n",
    "    * We hold over a portion of the data that we will use to test it\n",
    "    * In fact we devide our data in three:\n",
    "        * The Training set (around 70 or 80%): used to train our model\n",
    "        * The Development set: As we vary our models and features we use the development set to test the model, seeing how well it generalizes from the training data \n",
    "        * The Test or validation set: We keep this unseen while we play around with the model, we will use it in the end to see how our system performs outside of dev.\n",
    "    * Can Anyone tell me why it is important that we keep Train out of the loop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "# Create new dataframes for each corpus\n",
    "columns = tweetData.columns\n",
    "train = pd.DataFrame(columns=tweetData.columns)\n",
    "dev  = pd.DataFrame(columns=tweetData.columns)\n",
    "test  = pd.DataFrame(columns=tweetData.columns)\n",
    "# Divide the data one representative at a time\n",
    "for repHandle in tweetData[\"Handle\"].unique():\n",
    "    # For each representative send the first 140 (70%) tweets to train, 30(15%) to dev, the final 30(15%) to test\n",
    "    train = pd.concat([train, tweetData[tweetData.Handle == repHandle][:140]])\n",
    "    dev = pd.concat([dev, tweetData[tweetData.Handle == repHandle][140:170]])\n",
    "    test = pd.concat([test, tweetData[tweetData.Handle == repHandle][170:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A word on chance and metrics:\n",
    "* In order to say that our classifier is actually learning some insight from the training data it needs to at least beat chance:\n",
    "    * Just guessing we could be right 50%(1/ no of classes) of the time if the classes are balanced\n",
    "    * If there is a class that is more represented then just guessing that class will actually beat chance  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Republican    0.51344\n",
       "Democrat      0.48656\n",
       "Name: Party, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetData[\"Party\"].value_counts() /len(tweetData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chosing a Machine learning algorithm:\n",
    "\n",
    "* There are many tried and true methods for machine learning, most with bases in statistics or linear algebra, however it is not necesary to understand the mathematic intricacies behind them to make use of them, some of the most popular include:\n",
    "    * Naive Bayes:\n",
    "        * Straightforward application of bayessian statistics\n",
    "        * Naive because it makes the assumption that features are independant\n",
    "        * Easy to interpret\n",
    "    * Generalized Linear Models: \n",
    "        * Borrow from statistical regression and try to learn an optimal linear split of the problem space.\n",
    "        * Are better suited when we can expect the label to be a linear function (a sum of multiples) of the features.\n",
    "        * Can be used for classification via logistic regression\n",
    "        * Better with fewer features where it is likely that there will be a relatively clear cut relation\n",
    "    * Support vector machines (SVM):\n",
    "        * Effective in high dimensional spaces\n",
    "        * Very versatile, can be customised by the choice of kernel\n",
    "    * Decision tree classifiers:\n",
    "        * Find optimal cutouts to make a structured decision\n",
    "        * Higly interpretable by humans\n",
    "        * Less likely to be successful in situations with complex relations between features\n",
    "    * Neural Networks:\n",
    "        * Effective across a wide array of domains\n",
    "        * Can learn feature representations from unstructured data\n",
    "        * Widely adopted across fields\n",
    "        * Portable\n",
    "        * BUT: extremely hard to interpret, and often data hungry\n",
    "        \n",
    "For more go to http://scikit-learn.org/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model, please wait\n",
      "Model trained, testing on dev\n",
      "The model scored 0.5313271604938271%accuracy\n"
     ]
    }
   ],
   "source": [
    "# Train a model\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Prepare the data for the algorythm\n",
    "featurecolumns = columns[3:]\n",
    "#This contains only our features\n",
    "features = train[featurecolumns]\n",
    "#This contains the labels 0 for Dem, 1 for Rep\n",
    "labels = np.vectorize(lambda x: 1 if x == \"Republican\" else 0)(train[\"Party\"])\n",
    "# We have chosen a Multinomial Naive Bayes\n",
    "gnb1 = MultinomialNB()\n",
    "print(\"Training model, please wait\")\n",
    "gnb1.fit(features.values, labels)\n",
    "print(\"Model trained, testing on dev\")\n",
    "devfeatures = dev[featurecolumns]\n",
    "devlabels = np.vectorize(lambda x: 1 if x == \"Republican\" else 0)(dev[\"Party\"])\n",
    "score = gnb1.score(devfeatures,devlabels)\n",
    "print(\"The model scored {}%accuracy\".format(score) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are we not wasting a lot of information? \n",
    "## Why limit ourselves to just that small set of words?\n",
    "## Bring out the big guns, the Bag of Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bag of words features:\n",
    "# The count vectorizer is a tool that looks at a collection of texts and counts how many times each word appears\n",
    "# We import it and use iit to create a word matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizedCountsTrain = vectorizer.fit_transform(train[\"Tweet\"].values)\n",
    "vectorizedCountsDev = vectorizer.transform(dev[\"Tweet\"])\n",
    "vectorizedCountsTest = vectorizer.transform(test[\"Tweet\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model, please wait\n",
      "Model trained, testing on dev\n",
      "The model scored 0.7881944444444444%accuracy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#gnb = GaussianNB()\n",
    "gnb = MultinomialNB()\n",
    "\n",
    "print(\"Training model, please wait\")\n",
    "gnb.fit(vectorizedCountsTrain.toarray(), labels)\n",
    "print(\"Model trained, testing on dev\")\n",
    "score = gnb.score(vectorizedCountsDev.toarray(),devlabels)\n",
    "print(\"The model scored {}%accuracy\".format(score) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What to do while your model trains?\n",
    "\n",
    "* Keep working on reading your bibliography?\n",
    "* Go get a snack?\n",
    "* Catch up on your favourite comic books/tv-shows?\n",
    "* Any other time it's your chouce but today fill the survey!: <Survey link>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "class_labels = [\"Democrat\",\"Republican\"]\n",
    "\n",
    "top25 = np.argsort(gnb.coef_[0])[-100:]\n",
    "for index in top25:\n",
    "    print(\"{}: {}\".format(feature_names[index],gnb.coef_[0][index]))\n",
    "print(gnb.class_count_)\n",
    "print(gnb.classes_)\n",
    "print(len(gnb.coef_[0]))\n",
    "print(len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a support vector machine\n",
    "\n",
    "# Train a model\n",
    "from sklearn import svm\n",
    "# Prepare the data\n",
    "features = vectorizedCountsTrain\n",
    "labels = np.vectorize(lambda x: 1 if x == \"Republican\" else 0)(train[\"Party\"])\n",
    "\n",
    "clf = svm.SVC()\n",
    "print(\"Training model, please wait\")\n",
    "clf.fit(features, labels)\n",
    "print(\"Model trained, testing on dev\")\n",
    "devfeatures = vectorizedCountsDev\n",
    "devlabels = np.vectorize(lambda x: 1 if x == \"Republican\" else 0)(dev[\"Party\"])\n",
    "score = clf.score(devfeatures,devlabels)\n",
    "print(\"The model scored {}%accuracy\".format(score) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = gnb.score(devfeatures.toarray(),devlabels)\n",
    "# print(\"The model scored {}%accuracy\".format(score) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb1.class_count_\n",
    "gnb1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
